home: 
  home: Accueil
  welcome: Bienvenue sur mon portfolio professionnel !
  about: |
      Je suis Martin Majo, **lead d√©veloppeur**, **MLOps Engineer**.

      Avec bient√¥t 6 ans d'exp√©rience professionnelle dans le d√©veloppement de logiciels, j'ai acquis des comp√©tences en d√©veloppement de logiciels, en gestion de projet et en intelligence artificielle.

      **üëà S√©lectionnez mes exp√©riences dans le menu** pour d√©couvrir mon expertise !

  skills:
    primary: "Comp√©tences cl√©s :"
    other: "Autres comp√©tences :"
    bonus: |
      <p style='font-size:12px'>
      Cette liste n'est pas exhaustive et ne refl√®te que les domaines o√π j'ai le plus d'affinit√©s et d'expertise.
      </p>

  professional_experience:
    title: "Exp√©riences professionnelles :"
    description: "Description :"

    experiences:
      - company: Peaksys (Cdiscount)
        title: MLOps Engineer
        date: F√©vrier 2022 - Aujourd'hui ({years} ans et {months} mois)
        description: |
          Industrialisation des processus de d√©ploiement des mod√®les de machine Learning.  
          Conception, architecture et d√©veloppement de logiciel Python (librairies, modules).  
          Conception et animation de formations aupr√®s des Data Scientists.  
          D√©bogage et assistance aupr√®s des √©quipes DataScience.  
          Automatisation des tests fonctionnels.  
          Optimisation de code.  
        skills: 
          - Python 
          - Docker
          - Kubernetes
          - Azure DevOps
          - Datascience

      - company: Journ√©e de chasse
        title: Project Lead Developer
        date: Mars 2020 - Septembre 2021 (1 an et 6 mois)
        description: |
          Cr√©ation et management d'une √©quipe (2 devs & 1 ui/ux). Cr√©ation des nouvelles
          fonctionnalit√©s de la platform. √ätre en charge des serveurs, de l'optimisation 
          de la plateforme et de tout le c√¥t√© IT de l'entreprise (factures, SEO, AWS, ...).
        skills: 
          - Angular
          - NodeJS
          - AWS
          - SEO
          - IT
          - Management
          - Python
          - Stripe

      - company: Thales
        title: D√©veloppeur logiciel
        date: Ao√ªt 2019 - Mars 2020 (8 mois)
        description: |
          Cr√©ation d'une plateforme permettant de g√©rer plusieurs bancs
          d'essais directement depuis son navigateur plut√¥t que de devoir rester dans la
          salle des bancs.  
          Cr√©ation de rapports dynamiques sur tous les mat√©riels de Thales France.
        skills: 
          - Python
          - Birt
          - React

      - company: ShareYourTrip
        title: D√©veloppeur Full Stack
        date: fevrier 2018 - mars 2019 (1 an et 1 mois)
        description: |
          D√©veloppeur Full Stack pour shareyourtrip.fr
        skills: 
          - Symfony
          - Elasticsearch
          - AWS
          - Nginx
          - Python

      - company: Office Toner
        title: D√©veloppeur Back End
        date: avril 2017 - septembre 2017 (5 mois)
        description: |
          Optimisation et refactoring du site internet OfficeToner
        skills: 
          - Python
          - MongoDB
          - MySQL
          - PHP

      - company: Technicolor
        title: D√©veloppeur logiciel
        date: juillet 2015 - janvier 2016 (6 mois)
        description: |
          Cr√©ation d'un logiciel permettant le tri automatique des rushes (vid√©os produites 
          lors de tournages de films) du disque dur externe des clients au serveur interne 
          qui permet une optimisation du temps des monteurs et √©talonneurs.
        skills: 
          - Python
          - Qt
          - MySQL
  
  education:
    title: "Formations :"

    educations:
      - school: Epitech
        degree: Master en Informatique
        location: Bordeaux, France
        graduated_on: 2019
        link: https://www.epitech.eu/

  certification:
    title: "Certifications :"

    certifications:
      - title: Regression with scikit-learn
        school: DataScientest
        date: 2024
        link: https://files.datascientest.com/certification/0e65da50-fd3f-4000-844c-11ce2f3eeb40.pdf

      - title: Clustering with scikit-learn
        school: DataScientest
        date: 2024
        link: https://files.datascientest.com/certification/45bda0a7-51fc-4687-8df4-b0893ec1420c.pdf

      - title: Classification with scikit-learn
        school: DataScientest
        date: 2024
        link: https://files.datascientest.com/certification/e5e07605-8a1e-4d16-b5c8-e64e3d5f90f7.pdf

      - title: Advanced Classification with scikit-learn
        school: DataScientest
        date: 2024
        link: https://files.datascientest.com/certification/e2de37f4-59bd-45f4-b50f-89444cfe74c3.pdf

formations:
  page_title: Formation dispens√©es
  title: Formations aux Data Scientists de Cdiscount
  trainer: Formateur
  introduction_text: |
    En tant que **MLOps Engineer** chez Peaksys, j'ai eu l'opportunit√©, avec mon √©quipe, 
    de donner des formations aux data scientists sur divers sujets techniques essentiels pour leur travail quotidien. 
    Ces formations avaient pour but de les aider √† mieux comprendre l'environnement dans lequel ils √©voluent, 
    √† am√©liorer leurs comp√©tences techniques et √† adopter les meilleures pratiques en mati√®re de d√©veloppement logiciel.
  
  sujets_title: Sujets abord√©s
  sujets_text: |
    Nous avons couvert les sujets suivants lors de nos formations :

    - **Git** : Explication des bases de Git, comment versionner leur code et collaborer efficacement.
    - **Docker** : Introduction √† Docker, comment containeriser leurs applications pour des d√©ploiements reproductibles.
    - **Kubernetes** : Pr√©sentation de Kubernetes, comment orchestrer leurs conteneurs √† grande √©chelle.
    - **Azure DevOps** : Utilisation d'Azure DevOps pour g√©rer leurs projets, leurs pipelines CI/CD et leurs artefacts.
    - **Monitoring et Logs** : Explication de l'importance du monitoring, comment r√©cup√©rer et analyser les logs pour diagnostiquer les probl√®mes.
  
  objectifs_title: Objectifs des formations
  objectifs_text: |
    Les formations visaient √† atteindre les objectifs suivants :
    
    - Comprendre l'environnement de travail.
    - D√©ployer correctement leurs jobs et API.
    - Versionner efficacement leur code.
    - Adopter les bonnes pratiques de d√©veloppement et de documentation.
    - Apprendre les bases des tests unitaires et les int√©grer dans un pipeline CI/CD.

  pipeline_title: Mise en place d'un pipeline CI/CD
  pipeline_text: |
    Nous avons mis en place un pipeline de CI/CD pour leurs projets, 
    avec des exigences minimales de couverture de tests unitaires pour √©viter les dettes techniques.

  support_title: Support continu
  support_text: |
    Notre √©quipe √©tait √©galement pr√©sente pour les aider √† monter en comp√©tence sur les librairies Python que nous avions d√©velopp√©es. 
    Nous √©tions disponibles pour du support en cas de probl√®mes, les aidant √† r√©soudre les erreurs et √† comprendre les messages d'erreur.

  conclusion_text: |
    Gr√¢ce √† ces formations, les data scientists de Cdiscount ont pu am√©liorer leurs comp√©tences techniques et adopter des pratiques 
    de d√©veloppement logiciel de haute qualit√©, leur permettant de travailler de mani√®re plus efficace et de livrer des solutions robustes et bien document√©es.

tgi:
  page_title: TGI - Text Generation Inference
  title: Mise en place de TGI (Text Generation Inference) avec Hugging Face
  introduction_text: |
    Chez Peaksys, nous avons impl√©ment√© une API pour la g√©n√©ration de texte en utilisant 
    le framework [**Hugging Face**](https://huggingface.co/docs/text-generation-inference/index). Cette API permet de d√©ployer et de g√©rer plusieurs mod√®les de langage (LLMs) 
    open source, tels que **LLaMA3**, **Mixtral**, **Mistral**, et d'autres, afin de tester et d'√©valuer leurs performances.
  
  gestion_modeles_title: Gestion des Mod√®les
  gestion_modeles_text: |
    Notre infrastructure permet de d√©ployer plusieurs LLMs simultan√©ment, en attribuant des ressources sp√©cifiques 
    √† chacun d'eux. Chaque mod√®le peut √™tre assign√© √† un ou plusieurs GPUs particulier avec une quantit√© d√©finie de ressources, 
    garantissant ainsi que les autres mod√®les ne peuvent pas utiliser les ressources allou√©es si elles ne sont pas disponibles.
    
    - **Mod√®les support√©s** : LLaMA3, Mixtral, Mistral, et bien d'autres.
    - **Gestion des ressources** : Attribution sp√©cifique de GPU et de ressources en fonction des besoins de chaque mod√®le.
  
  ai_gateway_title: AI Gateway
  ai_gateway_text: |
    Nous avons mis en place une **AI Gateway** pour g√©rer les quotas et l'utilisation de chaque LLM/GPU en fonction des projets, 
    jobs, chats, utilisateurs, etc. Cette passerelle g√®re √©galement la s√©curit√©, l'authentification, et le monitoring. 
    Tout cela est en constante am√©lioration pour r√©pondre aux besoins changeants de notre infrastructure.

  technologies_title: Technologies Utilis√©es
  technologies_text: |
    Pour orchestrer et g√©rer notre infrastructure, nous utilisons les technologies suivantes :
    
    - **Kubernetes (K8s)** : Orchestration des conteneurs pour d√©ployer et g√©rer les mod√®les √† grande √©chelle.
    - **Helm** : Gestionnaire de packages pour Kubernetes, facilitant le d√©ploiement et la gestion des applications.
    - **Azure DevOps** : Plateforme de CI/CD pour automatiser les d√©ploiements et g√©rer le cycle de vie des applications.

  conclusion_text: |
    Gr√¢ce √† cette infrastructure, CDiscount et ses filiales peuvent utiliser ces LLMs de mani√®re simple et efficace, avec une 
    documentation compl√®te pour les guider. Cette solution offre des performances optimales et une gestion simplifi√©e des ressources, 
    permettant ainsi √† nos √©quipes de se concentrer sur le d√©veloppement et l'am√©lioration de leurs projets tout en b√©n√©ficiant de 
    mod√®les de langage performants et bien g√©r√©s.

jupyterhub:
  page_title: JupyterHub
  title: D√©ploiement de JupyterHub
  introduction_text: |
    Nous avons mis en place [**JupyterHub**](https://jupyter.org/hub) sur notre cluster Kubernetes pour offrir un environnement de d√©veloppement flexible et puissant √† nos utilisateurs. 
    Ce d√©ploiement permet √† nos data scientists et d√©veloppeurs de travailler efficacement avec des ressources adapt√©es √† leurs besoins sp√©cifiques.

  mise_en_place_title: Mise en place de JupyterHub
  mise_en_place_text: |
    La mise en place de **JupyterHub** sur notre infrastructure a impliqu√© plusieurs √©tapes cruciales :
    
    - **Cr√©ation des ingress** : Configuration des points d'entr√©e pour g√©rer le trafic vers les diff√©rentes instances de JupyterHub.
    - **Configuration des utilisateurs** : Gestion des acc√®s et des permissions pour diff√©rents utilisateurs.
    - **Ajout d'un plugin d'authentification pour l'OIDC interne** : Impl√©mentation d'un plugin pour l'authentification s√©curis√©e via notre fournisseur OIDC interne.
    - **D√©ploiement d'un proxy Traefik** : Utilisation de Traefik, recommand√© par la documentation de JupyterHub, pour g√©rer les routes et renforcer la s√©curit√©.

  creation_images_title: Cr√©ation d'Images Docker Personnalis√©es
  creation_images_text: |
    Nous avons cr√©√© des images Docker personnalis√©es pour les serveurs Jupyter afin de r√©pondre aux divers besoins de nos utilisateurs :
    
    - **Choix de ressources** : Les utilisateurs peuvent s√©lectionner des configurations sp√©cifiques de GPU, CPU et RAM.
    - **Gestion automatique des ressources** : Les serveurs utilisant des ressources intensives s'auto-√©teignent rapidement pour √©viter de monopoliser les ressources.
    - **Choix de la version de Python** : Possibilit√© de choisir diff√©rentes versions de Python pour les environnements de d√©veloppement.
    - **Images avec drivers GPU** : Disponibilit√© d'images incluant les drivers n√©cessaires pour GPU (CUDA, cuDNN).
    - **Page admin pour serveurs personnalis√©s** : Cr√©ation d'une interface administrative permettant de configurer des serveurs sur mesure avec des ressources suppl√©mentaires pour des utilisateurs sp√©cifiques sur une dur√©e limit√©e.
    - **Optimisation des images** : R√©duction de la taille des images Docker en minimisant les d√©pendances inutiles.

  gestion_stockage_title: Gestion du Stockage Local
  gestion_stockage_text: |
    Chaque serveur Jupyter est associ√© √† un stockage local restreint :
    
    - **Limitation du stockage** : Chaque serveur dispose d'un stockage local de 20GO maximum sur un Persistent Volume Claim (PVC).
    - **√âcriture en RAM** : Les utilisateurs peuvent √©crire en RAM plut√¥t que sur disque pour des performances optimales, particuli√®rement avantageux pour le chargement de mod√®les.

  maintenance_title: Maintenance Continue et Veille Technologique
  maintenance_text: |
    Nous assurons une mise √† jour r√©guli√®re des images de serveurs Jupyter ainsi que de JupyterHub et JupyterLab. 
    Avec l'avanc√©e rapide et l'utilisation croissante de l'IA g√©n√©rative, il est crucial de rester √† jour avec les derni√®res technologies et pratiques.

  conclusion_text: |
    En d√©ployant JupyterHub sur notre cluster Kubernetes, nous avons r√©ussi √† offrir une solution robuste et flexible 
    √† nos utilisateurs, leur permettant de b√©n√©ficier d'un environnement de d√©veloppement sur mesure. 
    Gr√¢ce √† une gestion fine des ressources et √† une infrastructure √©volutive, nos √©quipes peuvent se concentrer sur 
    l'innovation et l'optimisation de leurs projets, tout en profitant des derni√®res avanc√©es technologiques.
    
    Notre engagement √† maintenir cette infrastructure √† jour garantit que nous restons √† la pointe de la technologie 
    et que nous r√©pondons efficacement aux besoins changeants de nos utilisateurs.

mlflow:
  page_title: MLflow
  title: D√©ploiement de MLflow chez Peaksys
  introduction_title: Introduction √† MLflow
  introduction_text: |
    [**MLflow**](https://mlflow.org/) est une plateforme open source con√ßue pour g√©rer l'ensemble du cycle de vie des mod√®les de machine learning. 
    Il comprend plusieurs composants cl√©s, notamment :
    
    - **Model Registry** : Permet de g√©rer et de versionner les mod√®les de machine learning.
    - **Versionning de Mod√®le** : Suivi des diff√©rentes versions des mod√®les pour une meilleure gestion des d√©ploiements.
    - **Tracking des Mod√®les** : Enregistrement des param√®tres, des m√©triques et des artefacts des exp√©riences de machine learning.

    Chez Peaksys, nous avons d√©ploy√© MLflow pour centraliser et optimiser la gestion de nos mod√®les de machine learning.

  deployment_title: D√©ploiement de MLflow
  deployment_text: |
    Le d√©ploiement de MLflow chez Peaksys a impliqu√© plusieurs √©tapes cruciales :

    - **D√©ploiement d'un reverse proxy** : Utilisation de **oauth2_proxy** pour g√©rer l'authentification et la s√©curit√© des acc√®s √† MLflow.
    - **Cr√©ation des ingress** : Configuration des points d'entr√©e pour diriger le trafic vers le service MLflow.
    - **Cr√©ation de plugins pour MLflow** : D√©veloppement de plugins personnalis√©s pour am√©liorer les fonctionnalit√©s de MLflow.
        - **Authentification** : Plugin pour g√©rer l'authentification des utilisateurs.
        - **Gestion des versions de mod√®les** : Limitation du nombre maximum de versions de mod√®les pour √©viter l'encombrement. Les versions les plus anciennes sont automatiquement supprim√©es lorsque la limite est atteinte, sauf pour certains mod√®les qui b√©n√©ficient d'exceptions.
        - **Optimisation des ressources** : Utilisation de la RAM pour le stockage temporaire lors de l'envoi des mod√®les, afin de minimiser l'usage du stockage local.

  library_title: Librairie Python pour Data Scientists
  library_text: |
    Pour simplifier l'utilisation de MLflow par nos data scientists, nous avons d√©velopp√© une librairie Python surcouche de la librairie MLflow. 
    Cette librairie facilite l'int√©gration de MLflow dans leurs workflows quotidiens, en offrant des fonctionnalit√©s suppl√©mentaires et des abstractions 
    pour une utilisation plus intuitive et efficace.

  conclusion_text: |
    Gr√¢ce √† l'impl√©mentation de MLflow chez Peaksys, nous avons pu am√©liorer significativement notre gestion des mod√®les de machine learning. 
    Les fonctionnalit√©s avanc√©es et les plugins personnalis√©s que nous avons d√©velopp√©s permettent une gestion efficace et s√©curis√©e des mod√®les, 
    tout en optimisant l'utilisation des ressources. Nos data scientists peuvent d√©sormais se concentrer sur l'exp√©rimentation et l'innovation, 
    en s'appuyant sur une infrastructure solide et fiable.

argo:
  page_title: Argo Workflows
  title: D√©ploiement d'Argo Workflows
  introduction_title: Introduction √† Argo Workflows
  introduction_text: |
    [**Argo Workflows**](https://argoproj.github.io/workflows/) est un outil open-source de gestion de workflows con√ßu pour orchestrer les t√¢ches sur Kubernetes. 
    Il permet de d√©finir, planifier et g√©rer des workflows complexes de mani√®re efficace et √©volutive. 
    Chez Peaksys, nous avons d√©ploy√© Argo Workflows en production et sur tous nos environnements de d√©veloppement pour optimiser la gestion de nos jobs.

  pipeline_title: "Pipeline as Code"
  pipeline_text: |
    Pour automatiser le d√©ploiement des jobs Argo, nous avons cr√©√© un pipeline as code :
    
    - **D√©ploiement automatique des jobs** : Utilisation d'un pipeline as code pour g√©n√©rer et d√©ployer automatiquement les manifestes YAML n√©cessaires aux jobs Argo.
    - **Cr√©ation des manifestes YAML** : Le pipeline g√©n√®re les fichiers de configuration YAML, √©liminant ainsi les erreurs humaines et acc√©l√©rant le processus de d√©ploiement.

  orchestration_title: "Orchestration Efficace des Jobs"
  orchestration_text: |
    Argo Workflows permet une orchestration efficace des jobs, tant horizontalement que verticalement :
    
    - **Orchestration horizontale et verticale** : Possibilit√© de scinder les gros jobs en plusieurs petits jobs, 
      permettant une gestion plus fine des ressources et une meilleure performance globale.
    - **Gestion optimis√©e des ressources** : En r√©partissant les t√¢ches de mani√®re √©quilibr√©e, nous pouvons utiliser nos ressources de mani√®re plus efficace et √©viter les bottlenecks.

  conclusion_text: |
    Gr√¢ce √† l'impl√©mentation d'Argo Workflows chez Peaksys, nous avons pu am√©liorer significativement notre gestion des jobs. 
    L'automatisation via un pipeline as code et l'orchestration optimis√©e des ressources nous permettent de g√©rer nos workflows 
    de mani√®re plus efficace et robuste, tout en assurant une performance optimale.

tools:
  page_title: Images & Libs Python
  title: Outils Docker et Librairies Python
  docker_header: Images Docker Python
  docker_text: |
    Chez Peaksys, nous avons d√©velopp√© et maintenons des images Docker pour diff√©rentes versions de Python afin de r√©pondre aux besoins vari√©s de nos projets. 
    Nous g√©rons jusqu'√† quatre versions de Python, de la plus r√©cente √† n-3, tout en d√©pr√©ciant les versions plus anciennes.
    
    - **Versions de Python** : Chaque version de Python est disponible en plusieurs tailles de Debian (slim, alpine, buster, stretch, etc.) en fonction des besoins sp√©cifiques. 
    Cependant, nous nous concentrons de plus en plus sur la r√©duction de ces variations pour simplifier la gestion.
    
    - **Optimisation des images Docker** : Nous appliquons plusieurs techniques pour optimiser nos images Docker :
        - **Multi-stage build** : Construction multi-√©tape pour r√©duire la taille des images.
        - **Optimisation du local storage** : Gestion efficace du stockage local pour minimiser l'utilisation de l'espace disque.
        - **Cr√©ation des environnements et volumes** : Mise en place des environnements et volumes n√©cessaires pour notre cluster Kubernetes.
        - **Optimisation pour les librairies de datascience** : Ajustements sp√©cifiques pour les biblioth√®ques de datascience Python afin d'am√©liorer les performances.

  libraries_header: Librairies Python
  libraries_text: |
    Nous avons √©galement cr√©√© et maintenons plusieurs librairies Python sp√©cifiques √† la datascience. Ces librairies permettent √† nos data scientists 
    de travailler de mani√®re plus efficace, rapide, s√©curis√©e et propre. Voici quelques-unes de nos contributions majeures :
    
    - **Surcouches de biblioth√®ques existantes** : Nous avons d√©velopp√© des surcouches pour des biblioth√®ques populaires comme Luigi, MLflow, et Snowflake pour simplifier leur utilisation.
    - **Librairie de monitoring de KPI en temps r√©el** : Int√©gration avec Kafka pour surveiller les indicateurs de performance en temps r√©el.
    - **Librairie de s√©curit√©** : Gestion des appels s√©curis√©s en machine-to-machine (M2M) ou human-to-machine (H2M) avec notre OIDC interne.
    - **Librairie pour les tests unitaires** : Outils pour faciliter la cr√©ation de tests unitaires, Gherkin, et Wiremock.
    
    Ces librairies sont con√ßues pour aider nos data scientists √† √©crire du code plus lisible, maintenable et √©volutif, leur permettant de se concentrer sur l'innovation et la r√©alisation de projets ambitieux.

  conclusion_text: |
    L'objectif est de fournir des outils de haute qualit√© qui optimisent la productivit√© et l'efficacit√© des √©quipes. 
    Les images Docker et librairies Python jouent un r√¥le crucial dans l'infrastructure, soutenant une mission d'innovation continue et de livraison de solutions de data science de pointe.
    
    Une veille technique continue est effectu√©e pour rester √† la pointe des nouveaut√©s et des meilleures pratiques, garantissant ainsi que les outils et processus √©voluent avec les avanc√©es technologiques.